{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fe5b554-b094-4c6f-975f-5142f082b7a8",
   "metadata": {},
   "source": [
    "**installing and importing useful libraries**"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T10:05:46.689432Z",
     "start_time": "2025-10-12T10:05:46.684074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(plt.style.available)"
   ],
   "id": "1adebfbb2aee8411",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "9a2f0f6f-c322-4fd3-b08e-5d934c84cfad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-12T10:06:51.225863Z",
     "start_time": "2025-10-12T10:06:51.212120Z"
    }
   },
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# Numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_theme()\n",
    "\n",
    "#importing optimization techniques\n",
<<<<<<< Updated upstream
    "from implementations import *"
   ],
   "outputs": [],
   "execution_count": 6
=======
    "from implementations import *\n",
    "from cross_validation import *"
   ]
>>>>>>> Stashed changes
  },
  {
   "cell_type": "markdown",
   "id": "aa20b222-c0c6-4fdd-b500-885542b16cb3",
   "metadata": {},
   "source": [
    "**importing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a5b36-c5a1-426f-a6eb-15117ba48dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from dataprocessing section...\n",
    "# so we have x_train and y_train dataprocessed IMPORTANT y _train must be from {-1, 1} values to {0, 1} values and dataprocessed as well (clean outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7488fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT THE DATA TO CREATE A VALIDATION SET AND A TRAIN SET 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERSAMPLING AND BALANCING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea7578a-8712-481d-a6d8-9a12ba3e71dd",
   "metadata": {},
   "source": [
    "### Hyperparameters definition and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = [ 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2]  # regularization parameters list\n",
    "gammas = [1e-4, 1e-3, 1e-2, 1e-1, 1] # step-size parameters list\n",
    "max_iters = [1e2, 1e3, 1e4, 1e5] # max iters list\n",
    "\n",
    "\n",
    "def compute_auc(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    AUC calculation using Mann-Whitney statistics\n",
    "    Inputs : \n",
    "            - y_true : numpy array containing the real {0, 1} values of the dataset\n",
    "            - y_scores : numpy array containing our predictions\n",
    "    Output : \n",
    "            AUC Area under the ROC curve \n",
    "    \"\"\"\n",
    "    order = np.argsort(y_scores)\n",
    "    y_true_sorted = y_true[order]\n",
    "\n",
    "    n_pos = np.sum(y_true)\n",
    "    n_neg = len(y_true) - n_pos\n",
    "\n",
    "    # rank positions \n",
    "    rank_positions = np.arange(1, len(y_true_sorted) + 1)\n",
    "    rank_sum = np.sum(rank_positions[y_true_sorted == 1])\n",
    "\n",
    "    # AUC using Mannâ€“Whitney\n",
    "    auc = (rank_sum - n_pos*(n_pos+1)/2) / (n_pos * n_neg)\n",
    "    return auc\n",
    "\n",
    "def compute_accuracy(y_true, y_scores) : \n",
    "    \"\"\"\n",
    "    Accuracy computation\n",
    "    Inputs : \n",
    "            - y_true : numpy array containing the real {0, 1} values of the dataset\n",
    "            - y_scores : numpy array containing our predictions\n",
    "    Output : \n",
    "            Accuracy = correct predictions / total predictions %\n",
    "\n",
    "    \"\"\"\n",
    "    correct_pred = (y_true == y_scores)\n",
    "    accuracy = np.mean(correct_pred) * 100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa264a6",
   "metadata": {},
   "source": [
    "### K-fold cross validation functions"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def make_balanced_subset(x_train_filtered, y_train, majority_class=-1, minority_class=1,\n",
    "                         seed_major=0, seed_minor=42, seed_shuffle=7):\n",
    "    # Boolean masks\n",
    "    maj_mask = (y_train == majority_class)\n",
    "    min_mask = (y_train == minority_class)\n",
    "\n",
    "    # Indices per class\n",
    "    maj_idx = np.nonzero(maj_mask)[0]\n",
    "    min_idx = np.nonzero(min_mask)[0]\n",
    "\n",
    "    # Target size = size of minority (undersample majority)\n",
    "    n = len(min_idx)\n",
    "\n",
    "    # Sample without replacement\n",
    "    rs_maj = np.random.RandomState(seed_major)\n",
    "    rs_min = np.random.RandomState(seed_minor)\n",
    "    sampled_maj = rs_maj.choice(maj_idx, size=n, replace=False)\n",
    "    sampled_min = rs_min.choice(min_idx, size=n, replace=False)\n",
    "\n",
    "    # Combine and shuffle\n",
    "    balanced_idx = np.concatenate([sampled_maj, sampled_min])\n",
    "    rs_shuf = np.random.RandomState(seed_shuffle)\n",
    "    rs_shuf.shuffle(balanced_idx)\n",
    "\n",
    "    # Slice arrays\n",
    "    x_bal = x_train_filtered[balanced_idx]\n",
    "    y_bal = y_train[balanced_idx]\n",
    "    return x_bal, y_bal, balanced_idx\n",
    "\n",
    "x_train_balanced, y_train_balanced, balanced_indices = make_balanced_subset(\n",
    "    x_train_filtered, y_train,\n",
    "    majority_class=-1, minority_class=1,\n",
    "    seed_major=0, seed_minor=42, seed_shuffle=7\n",
    ")\n",
    "\n",
    "# x_train_balanced.shape, y_train_balanced.shape\n"
   ],
   "id": "6e037f021edc1a98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9431e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_k_indices(N, k_fold, seed=21): \n",
    "    \"\"\"build k indices for k-fold.\n",
    "\n",
    "    Args:\n",
    "        N:      num of samples\n",
    "        k_fold: K in K-fold, i.e. the fold num\n",
    "        seed:   the random seed\n",
    "\n",
    "    Returns:\n",
    "        A 2D array of shape=(k_fold, N/k_fold) that indicates the data indices for each fold\n",
    "\n",
    "    \"\"\"\n",
    "    num_row = N\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval : (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "     \n",
    "\n",
    "def k_fold_cross_validation(y_train, x_train, lambdas, gammas, max_iters, k_fold, methods, seed, initial_w) :\n",
    "    # dictionary to contain the best method with the best parameters and its metrics\n",
    "    best_overall = {\"method\": \"\", \"lambda\": 0, \"gamma\": 0, \"max_iter\": 0, \"train loss\": 0, \"test loss\": 0, \"AUC\": 0, \"accuracy\": 0, \"y_pred\" : None, \"w_opt\": None}\n",
    "    results =[] # to keep the best results per method\n",
    "    #creating k folders on the train set \n",
    "    k_indices = build_k_indices(len(y_train), k_fold, seed)\n",
    "\n",
    "    for method in methods : #scrolling methods\n",
    "        best_per_method =  {\"method\": \"\", \"lambda\": 0, \"gamma\": 0, \"max_iter\": 0, \"train loss\": 0, \"test loss\": 0, \"AUC\": 0, \"accuracy\": 0, \"y_pred\" : None, \"w_opt\": None} \n",
    "        for lam in lambdas : # scrolling lambdas\n",
    "            for gam in gammas : #scrolling gammas\n",
    "                for max_it in max_iters : #scrolling iters ----> model defined at this point\n",
    "                    logistic_loss_tr = []\n",
    "                    logistic_loss_te =[]\n",
    "                    AUC=  []\n",
    "                    accuracies = []\n",
    "                    \n",
    "                    for k in range(k_fold) : \n",
    "                        #k-th subgroup in test, others in train\n",
    "                        test_mask = np.isin(np.arange(len(y_train)), k_indices[k, :])\n",
    "                        y_test_k = y_train[test_mask]\n",
    "                        x_test_k = x_train[test_mask]\n",
    "    \n",
    "                        y_train_k=y_train[~test_mask]\n",
    "                        x_train_k=x_train[~test_mask]\n",
    "\n",
    "                        #ADD OVERSAMPLING TO TRAIN SET !!!!!\n",
    "\n",
    "                        #train the model\n",
    "                        if method == \"reg_logistic regression\" :\n",
    "                            w_opt, loss = reg_logistic_regression(y_train_k, x_train_k,lam, np.zeros(x_train_k.shape[1]), max_it, gam)\n",
    "                        elif method == \"least_squares\" :\n",
    "                            w_opt, loss = least_squares(y_train_k, x_train_k)\n",
    "                        elif method == \"adam_reg_logistic regression\":\n",
    "                            w_opt, loss = reg_logistic_regression_adam(y_train_k, x_train_k, lam, np.zeros(x_train_k.shape[1]), max_it, 0.9, 0.999, gam, 700 )\n",
    "                        elif method == \"ridge_regression\" :\n",
    "                            w_opt, loss = ridge_regression(y_train_k, x_train_k, lam)\n",
    "\n",
    "                        #computing metrics \n",
    "                        logistic_loss_tr.append(compute_logistic_loss(y_train_k, x_train_k, w_opt)) #without penalizing term\n",
    "                        logistic_loss_te.append(compute_logistic_loss(y_test_k, x_test_k, w_opt)) #without penalizing term CAPIRE CHE SENSO HA COMPARARE STE LOSS\n",
    "\n",
    "                        if method in [\"logistic_regression\", \"reg_logistic_regression\"]:\n",
    "                            pred = sigmoid(x_test_k @ w_opt) \n",
    "                        else:\n",
    "                            pred = x_test_k @ w_opt\n",
    "\n",
    "                        AUC.append(compute_auc(y_test_k, pred))\n",
    "                        accuracies.append(compute_accuracy(y_test_k, (pred >= 0.5).astype(int)))\n",
    "                    # updating    \n",
    "                    if np.mean(AUC) > best_per_method[\"AUC\"]:\n",
    "                        best_per_method.update({\"method\": method, \"gamma\": gam, \"lambda_\": lam, \"max_iter\": max_it, \"train loss\": np.mean(logistic_loss_tr), \"test loss\": np.mean(logistic_loss_te), \"AUC\": np.mean(AUC), \"accuracy\": np.mean(accuracies), \"y_pred\" : (pred >= 0.5).astype(int) , \"w_opt\": w_opt})\n",
    "\n",
    "                    if np.mean(AUC) > best_overall[\"AUC\"]:\n",
    "                        best_overall.update({\"method\": method, \"gamma\": gam, \"lambda_\": lam, \"max_iter\": max_it, \"train loss\": np.mean(logistic_loss_tr), \"test loss\": np.mean(logistic_loss_te), \"AUC\": np.mean(AUC), \"accuracy\": np.mean(accuracies), \"y_pred\" : (pred >= 0.5).astype(int) , \"w_opt\": w_opt})\n",
    "\n",
    "        results.append(best_per_method)\n",
    "        print(\"For the method %s the best hyperparamters, with respect to AUC, are : \\n\" % method)\n",
    "        print(\"lambda : %f, \" % best_per_method[\"lambda\"])\n",
    "        print(\"gamma : %f, \" % best_per_method[\"gamma\"])\n",
    "        print(\"max_iter : %i \" % best_per_method[\"max_iter\"])\n",
    "\n",
    "    print(\"the best method wrt AUC is %s with the following hyperparameters: \\n\" % best_overall[\"method\"])\n",
    "    print(\"lambda : %f, \" % best_overall[\"lambda\"])\n",
    "    print(\"gamma : %f, \" % best_overall[\"gamma\"])\n",
    "    print(\"max_iter : %i \" % best_overall[\"max_iter\"])\n",
    "\n",
    "\n",
    "    return best_overall, results \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab264da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC calcolata manualmente: 0.64\n",
      "AUC con scikit-learn: 0.64\n",
      "Differenza: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cross_validation_visualization(param_grid, logistic_loss_tr, logistic_loss_te)\n",
    "\n",
    "num_par = len(param_grid)\n",
    "w = 0.3 # bar width\n",
    "pos = np.arange(num_par)\n",
    "plt.bar(pos - w, AUC, width = w, label='AUC' )\n",
    "plt.bar(pos, accuracies, width=w, label= 'Accuracy')\n",
    "plt.bar(pos + w, logistic_loss_tr, width = w, label = 'train logistic loss' )\n",
    "plt.bar(pos + w, logistic_loss_te, width=w, label= \"test logistic loss\" )\n",
    "\n",
    "plt.xticks(pos, param_grid)\n",
    "plt.xlabel('Different regularization hyperparameter values')\n",
    "plt.title('Finding the best regularization hyperparamter - ADAM case')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b5d4d1",
   "metadata": {},
   "source": [
    "Now that we have found the best regularization hyperparameter for Adam reg log and GD reg log, let's test which model is the best to make predictions using a k-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63de39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CONFRONTING ALL THE MODELS WITH K-FOLD CROSS VALIDATION \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "N = len(y_train)\n",
    "d = x_train.shape[1]\n",
    "k = 10  # folds\n",
    "initial_w = np.zeros(d, )\n",
    "max_iters = 10000\n",
    "gamma = 0.01\n",
    "beta_1 = 0.9 #using Adam paper as benchmark\n",
    "beta_2 = 0.999 #using Adam paper as benchmark\n",
    "mini_batch_size = 700 #using Adam paper as benchmark \n",
    "\n",
    "models = [\n",
    "    (\"MSE GD\", lambda: mean_squared_error_gd(initial_w=initial_w, max_iters=max_iters, gamma=gamma)),\n",
    "    (\"MSE SGD\", lambda: mean_squared_error_sgd(initial_w=initial_w, max_iters=max_iters, gamma=gamma, mini_batch_size=mini_batch_size)),\n",
    "    (\"Least Squares\", lambda: least_squares()),\n",
    "    (\"Ridge Regression\", lambda: ridge_regression()), #understand which lambda here \n",
    "    (\"Logistic Regression GD\", lambda: logistic_regression(initial_w=initial_w, max_iters=max_iters, gamma=gamma)),\n",
    "    (\"Reg Logistic ADAM\", lambda: reg_logistic_regression_adam(lambda_adam, initial_w=initial_w, max_iters=max_iters,  beta_1=beta_1, beta_2=beta_2,gamma=gamma, mini_batch_size=mini_batch_size)),\n",
    "    (\"Reg Logistic GD\", lambda: reg_logistic_regression(lambda_gd, initial_w=initial_w, max_iters=max_iters, gamma=gamma))\n",
    "]  ### does it make sense to include all the models ????\n",
    "\n",
    "\n",
    "#### validation metrics\n",
    "logistic_loss_tr = []\n",
    "logistic_loss_te =[]\n",
    "AUC=  []\n",
    "accuracies = []\n",
    "\n",
    "####  k-fold cross validation\n",
    "k_indices =build_k_indices(N, k_fold, seed)\n",
    "for model in models:\n",
    "    fold_loss_tr = 0\n",
    "    fold_loss_te = 0\n",
    "    fold_AUC = 0\n",
    "    fold_accuracy = 0\n",
    "\n",
    "    for k in range(k_fold):\n",
    "        #k-th subgroup in test, others in train\n",
    "        test_mask = np.isin(np.arange(len(y)), k_indices[k, :])\n",
    "        y_test_k = y_train[test_mask]\n",
    "        x_test_k = x_train[test_mask]\n",
    "    \n",
    "        y_train_k=y_train[~test_mask]\n",
    "        x_train_k=x_train[~test_mask]\n",
    "    \n",
    "        # train the model\n",
    "        name, model_fn = model\n",
    "        w_opt, loss_tr = model_fn(y_train_k, x_train_k)\n",
    "    \n",
    "        # calculate the loss for test data\n",
    "        loss_te = compute_logistic_loss(y_test_k, x_test_k, w_opt)\n",
    "\n",
    "        # compute AUC \n",
    "        predictions = sigmoid (x_test_k @ w_opt)\n",
    "        AUC = compute_auc(y_test_k, predictions)\n",
    "\n",
    "        # compute accuracy\n",
    "        y_pred = (predictions >= 0.5).astype(int)\n",
    "        accuracy = np.mean(y_pred == y_test)\n",
    "       \n",
    "\n",
    "        # storing validation results\n",
    "        fold_loss_tr += loss_tr\n",
    "        fold_loss_te+=loss_te\n",
    "        fold_AUC += AUC\n",
    "        fold_accuracy += accuracy\n",
    "    logistic_loss_tr.append(fold_loss_tr/k_fold)\n",
    "    logistic_loss_te.append(fold_loss_te/k_fold)\n",
    "    AUC.append(fold_AUC/k_fold)\n",
    "    accuracies.append(fold_accuracy/k_fold)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Plotting results per model   \n",
    "\n",
    "num_models = len(models)\n",
    "w = 0.3\n",
    "pos = np.arange(num_models)\n",
    "labels = [name for name, _ in models]\n",
    "\n",
    "plt.bar(pos - w, AUC, width=w, label='AUC')\n",
    "plt.bar(pos, accuracies, width=w, label='Accuracy')\n",
    "plt.bar(pos + w, logistic_loss_te, width=w, label='test logistic loss')\n",
    "plt.bar(pos + 2*w, logistic_loss_tr, width=w, label='train logistic loss')\n",
    "\n",
    "plt.xticks(pos, labels, rotation=45)\n",
    "plt.xlabel('Different models')\n",
    "plt.title('Finding the best model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
