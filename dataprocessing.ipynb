{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import create_csv_submission\n",
    "from helpers import load_csv_data\n",
    "from implementations import mean_squared_error_gd, mean_squared_error_sgd, least_squares, ridge_regression, logistic_regression, reg_logistic_regression, sigmoid"
   ],
   "id": "a678a924007c2dbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"data/dataset\", sub_sample=False)\n",
   "id": "643e80b6244537ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>Performing manual analysis</h3>",
   "id": "be8c5c509493453a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We start by looking into the data and removing data corresponding to identifiers and administrative codes and those corresponding to dates and times.\n",
    "Moreover, we want to drop the features when the percentage of missing values is higher than an optimal percentage (check the references in the report and explanations)."
   ],
   "id": "fbbfd6592febbca5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we need to look into the Data and check how many data remain if we choose a certain percentage of missing values. For that purpose we need to plot the number of remaining features according to the chosen threshold.",
   "id": "ce2dac0e848196bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h5>x-axis = thresholds (% of missingness allowed).</h5>\n",
    "<h5>y-axis = number of features with at most that much missing data.</h5>\n",
    "The bar plot shows how strict or lenient we can be with missingness.\n",
    "<h5>Left side (low threshold): shows how many features are almost complete.</h5>\n",
    "<h5>Right side (higher threshold): shows how many features remain if you allow more missing data.</h5>\n",
    "<h5>We can use it to decide: “If I drop all features with more than 20% missing values, how many features will I keep?”</h5>"
   ],
   "id": "bf5e16f38b735ad5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "CSV_PATH = \"data/dataset/x_train.csv\"\n",
    "\n",
    "# 1) read headers\n",
    "with open(CSV_PATH, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    headers = next(reader)[1:]\n",
    "    feature_names = next(reader)\n",
    "\n",
    "# 2) load numeric data (skip header row)\n",
    "X = np.genfromtxt(\n",
    "    CSV_PATH,\n",
    "    delimiter=\",\",\n",
    "    skip_header=1,\n",
    "    dtype=float,\n",
    "    missing_values=(\"\",\"7\",\"77\",\"777\",\"9\",\"99\",\"999\", \"88\"),\n",
    "    filling_values=np.nan\n",
    ")\n",
    "\n",
    "# 3) compute % missing\n",
    "missing_pct = np.isnan(X).mean(axis=0) * 100\n",
    "thresholds = np.arange(0, 101, 5)\n",
    "feature_counts = [(missing_pct <= threshold).sum() for threshold in thresholds]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(thresholds, feature_counts, color='b', width=4)\n",
    "plt.xlabel('Threshold % of missing data')\n",
    "plt.ylabel('Number of features with at most x% missing data')\n",
    "plt.title('Number of features with at most x% missing data')\n",
    "plt.xticks(thresholds)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.savefig(\"plot.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 4) keep features with ≤40% missing\n",
    "mask40 = missing_pct <= 40\n",
    "X = X[:, mask40]\n",
    "feature_names = [name for i, name in enumerate(feature_names) if mask40[i]]\n",
    "\n",
    "# 5) remove specific administrative/date/ID columns\n",
    "remove_cols = ['Id', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR',\n",
    "               'DISPCODE', 'SEQNO', '_PSU', 'QSTVER', 'MSCODE', '_STSTR']\n",
    "remove_idx = [i for i, name in enumerate(feature_names) if name in remove_cols]\n",
    "\n",
    "X_reduced = np.delete(X, remove_idx, axis=1)\n",
    "feature_names_reduced = [name for i, name in enumerate(feature_names) if i not in remove_idx]\n",
    "\n",
    "# 6) check results\n",
    "print(\"Final shape:\", X_reduced.shape)\n",
    "print(\"Remaining features:\", len(feature_names_reduced))\n",
    "print(\"kept features:\", feature_names_reduced)\n"
   ],
   "id": "ca6a697cb76f5964"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### We have decided to keep features with missing data up to 40% after plot analysis and some article readings.\n",
    "\n",
    "#### 1. Demographics (baseline predictors)\n",
    "- `SEX`\n",
    "- `AGEG5YR`, `_AGE65YR` (senior flag), `_AGE80` (80+)\n",
    "- `INCOME2`, `_INCOMG`\n",
    "- `MARITAL`\n",
    "- `EMPLOY1`\n",
    "- `RENTHOM1`\n",
    "- `CHILDREN`, `_CHLDCNT`\n",
    "- `_RACE`, `_PRACE1`, `_HISPANC` (broad + detailed race/ethnicity)\n",
    "\n",
    "#### 2. General health & healthcare access\n",
    "- `GENHLTH`\n",
    "- `PHYSHLTH`\n",
    "- `MENTHLTH`\n",
    "- `HLTHPLN1` (health coverage)\n",
    "- `PERSDOC2` (personal doctor)\n",
    "- `MEDCOST` (cost barrier)\n",
    "- `CHECKUP1` (routine checkup)\n",
    "\n",
    "#### 3. Chronic conditions\n",
    "- `BPHIGH4` (high blood pressure)\n",
    "- `BLOODCHO`, `CHOLCHK`, `TOLDHI2` (cholesterol)\n",
    "- `CVDSTRK3` (stroke)\n",
    "- `ASTHMA3`\n",
    "- `CHCSCNCR`, `CHCOCNCR` (cancers)\n",
    "- `CHCCOPD1` (COPD)\n",
    "- `HAVARTH3` (arthritis)\n",
    "- `ADDEPEV2` (depression)\n",
    "- `CHCKIDNY` (kidney disease)\n",
    "- `DIABETE3` (diabetes)\n",
    "\n",
    "#### 4. Behaviors – smoking, alcohol, diet, exercise, prevention\n",
    "- **Smoking:** `SMOKE100`, `USENOW3`, `_SMOKER3`, `_RFSMOK3`\n",
    "- **Alcohol:** `ALCDAY5`, `DRNKANY5`, `_RFBING5`, `_RFDRHV5`\n",
    "- **Diet:** `FRUIT1`, `FVGREEN`, `FVORANG`, `VEGETAB1`, `FRUITJU1`, `FVBEANS`, `_FRUTSUM`, `_VEGESUM`, `_FRTLT1`, `_VEGLT1`\n",
    "- **Physical activity:** `EXERANY2`, `_TOTINDA`, `STRENGTH`, `_PA150R2`, `_PA300R2`, `_PASTRNG`\n",
    "- **Safety & prevention:** `SEATBELT`, `FLUSHOT6`, `PNEUVAC3`, `HIVTST6`\n",
    "\n",
    "#### 5. Anthropometrics\n",
    "- `WEIGHT2`, `HEIGHT3`, `WTKG3`\n",
    "- `_BMI5`, `_BMI5CAT`, `_RFBMI5`\n",
    "\n",
    "#### 6. Psychosocial / functional health\n",
    "- `QLACTLM2` (activity limitation)\n",
    "- `USEEQUIP` (equipment use for disability)\n",
    "- `BLIND`\n",
    "- `DECIDE` (cognitive difficulties)\n",
    "- `DIFFWALK`, `DIFFDRES`, `DIFFALON`\n"
   ],
   "id": "189dbd647d1edd11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "263d27bdb509e81d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "kept_features = [\n",
    "    # 1. Demographics\n",
    "    \"SEX\", \"AGEG5YR\", \"_AGE65YR\", \"_AGE80\",\n",
    "    \"INCOME2\", \"_INCOMG\", \"MARITAL\", \"EMPLOY1\",\n",
    "    \"RENTHOM1\", \"CHILDREN\", \"_CHLDCNT\",\n",
    "    \"_RACE\", \"_PRACE1\", \"_HISPANC\",\n",
    "\n",
    "    # 2. General health & healthcare access\n",
    "    \"GENHLTH\", \"PHYSHLTH\", \"MENTHLTH\",\n",
    "    \"HLTHPLN1\", \"PERSDOC2\", \"MEDCOST\", \"CHECKUP1\",\n",
    "\n",
    "    # 3. Chronic conditions\n",
    "    \"BPHIGH4\", \"BLOODCHO\", \"CHOLCHK\", \"TOLDHI2\",\n",
    "    \"CVDSTRK3\", \"ASTHMA3\", \"CHCSCNCR\", \"CHCOCNCR\",\n",
    "    \"CHCCOPD1\", \"HAVARTH3\", \"ADDEPEV2\",\n",
    "    \"CHCKIDNY\", \"DIABETE3\",\n",
    "\n",
    "    # 4. Behaviors – smoking, alcohol, diet, exercise, prevention\n",
    "    \"SMOKE100\", \"USENOW3\", \"_SMOKER3\", \"_RFSMOK3\",\n",
    "    \"ALCDAY5\", \"DRNKANY5\", \"_RFBING5\", \"_RFDRHV5\",\n",
    "    \"FRUIT1\", \"FVGREEN\", \"FVORANG\", \"VEGETAB1\",\n",
    "    \"FRUITJU1\", \"FVBEANS\", \"_FRUTSUM\", \"_VEGESUM\",\n",
    "    \"_FRTLT1\", \"_VEGLT1\",\n",
    "    \"EXERANY2\", \"_TOTINDA\", \"STRENGTH\",\n",
    "    \"_PA150R2\", \"_PA300R2\", \"_PASTRNG\",\n",
    "    \"SEATBELT\", \"FLUSHOT6\", \"PNEUVAC3\", \"HIVTST6\",\n",
    "\n",
    "    # 5. Anthropometrics\n",
    "    \"WEIGHT2\", \"HEIGHT3\", \"WTKG3\",\n",
    "    \"_BMI5\", \"_BMI5CAT\", \"_RFBMI5\",\n",
    "\n",
    "    # 6. Psychosocial / functional health\n",
    "    \"QLACTLM2\", \"USEEQUIP\", \"BLIND\",\n",
    "    \"DECIDE\", \"DIFFWALK\", \"DIFFDRES\", \"DIFFALON\"\n",
    "]\n",
    "count = len(kept_features)\n",
    "print(\"Number of features kept:\", count)\n"
   ],
   "id": "bff20433c617c7a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>Now we perform first data preprocessing</h3>",
   "id": "278ef7329b48c0db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x = [i in kept_features for i in headers] #headers filtering\n",
    "\n",
    "new_headers = [] # to maintain the order\n",
    "for i in headers:\n",
    "    if i in kept_features:\n",
    "        new_headers.append(i) #makes a list of only the kept features, preserve the original order\n",
    "\n",
    "mapping = {new_headers[i]:i for i in range(len(new_headers))} # Builds a dictionary linking each feature name to its column index in the reduced dataset, for preprocessing"
   ],
   "id": "332761083e6cc35e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"mask length (x):\", len(new_headers))"
   ],
   "id": "8f1215d3603fd4e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#reduction of number of columns from 321 to 75\n",
    "x_train_filtered = x_train[:,x] #keeps only the columns where the mask is True.\n",
    "x_test_filtered = x_test[:,x]  #Ensures both train and test are filtered in the exact same way.\n",
    "x_list = [x_train_filtered, x_test_filtered] #for the purpose of preprocessing the 2 sets in the same way"
   ],
   "id": "72b958bc1200ae71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "DATA CLEANING : \n",
    "- separate numerical features from categorical features\n",
    "- univariate outliers detection fro rough cleaning \n",
    "- multivariate outliers detection for final cleaning\n"
   ],
   "id": "a6a520aca6b231d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#checking which variables, if any, are numerical\n",
    "numerical_headers= []\n",
    "for i in new_headers :\n",
    "    if len(np.unique(x_train_filtered[:, mapping[i]], )) > 20: #considering them continuous numerical features if they can have more than 20 different values\n",
    "        numerical_headers.append(i)   \n",
    "\n",
    "print(len(numerical_headers))\n",
    "print(numerical_headers)\n"
   ],
   "id": "fe95bbd40a30a2d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For each numerical variable we check if there are some elements in the sample that are too distant from the others",
   "id": "1e4a8517547f7267"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#visualization --- > plots saved in features plots, don't run again\n",
    "num_numerical = len(numerical_headers)\n",
    "\n",
    "for i, header in enumerate(numerical_headers):\n",
    "    plt.figure(figsize=(10, 6)) \n",
    "    plt.scatter(\n",
    "        np.arange(x_train_filtered.shape[0]),\n",
    "        x_train_filtered[:, mapping[header]],\n",
    "        color=\"blue\",\n",
    "        marker=\"o\",\n",
    "        label=header\n",
    "    )\n",
    "    plt.title(header)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    plt.savefig(f\"{header}.png\")  \n",
    "    \n",
    "    \n",
    "    #plt.show()\n",
    "\n"
   ],
   "id": "4714ed240a5b88b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#replacing nans with the median value of the same feature \n",
    "\n",
    "for i in new_headers : \n",
    "    col = x_train_filtered[:, mapping[i]]\n",
    "    median = np.nanmedian(col)\n",
    "    mask_nan = np.isnan(col)\n",
    "    col[mask_nan] = median\n",
    "    x_train_filtered[:, mapping[i]] = col"
   ],
   "id": "a72493f5bf28fa8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "we apply IQR algorithm for univariate outliers detection for a rough cleaning of data",
   "id": "53d327c4a1c806a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#import sys, importlib\n",
    "#sys.path.insert(0, r'C:\\\\Users\\\\sanni\\\\OneDrive\\\\Desktop\\\\POLIMI\\\\EPFL\\\\ML\\\\Project_1\\\\project-1-girl_power')\n",
    "\n",
    "import outliers\n",
    "#importlib.reload(outliers)  \n",
    "\n",
    "outliers_indexes = []\n",
    "\n",
    "\n",
    "\n",
    "for i in numerical_headers : \n",
    "    outliers_indexes.append(outliers.iqr(x_train_filtered[:, mapping[i]], 0.01, 0.99))\n",
    "\n",
    "outliers_indexes = np.unique([idx for sublist in outliers_indexes for idx in sublist]) #removing doubles\n",
    "\n",
    "print(outliers_indexes)\n",
    "print(outliers_indexes.shape)\n",
    "print(x_train.shape[0])"
   ],
   "id": "453af7a545253021"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We then apply the FAST-MCD algorithm for multivariate outliers analysis",
   "id": "668a641b54c08a8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys, importlib\n",
    "sys.path.insert(0, r'C:\\\\Users\\\\sanni\\\\OneDrive\\\\Desktop\\\\POLIMI\\\\EPFL\\\\ML\\\\Project_1\\\\project-1-girl_power')\n",
    "\n",
    "import outliers\n",
    "importlib.reload(outliers)  \n",
    "\n",
    "\n",
    "indices = [mapping[h] for h in numerical_headers]\n",
    "X_num = x_train_filtered[:, indices]\n",
    "\n",
    "\n",
    "h_val = int(0.75 * len(y_train))\n",
    "\n",
    "best_mu, best_Sigma, best_d = outliers.fast_mcd(X_num, h_val, 10, 1000, 1e-6, 1)\n",
    "\n",
    "print(best_mu)\n",
    "print(best_Sigma)\n",
    "print(best_d)"
   ],
   "id": "5adc536b006e52e"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
